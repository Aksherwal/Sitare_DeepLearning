{\n  "cells": [\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "# Neural Network Comparison Notebook"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## Introduction"\n        "In this notebook, we will compare four different neural network architectures: SimpleCNN, DeepNeuralNetwork, LeNetStyleCNN, and MiniResNet. We will evaluate their performance across five datasets: MNIST, Fashion-MNIST, CIFAR-10, SVHN, and STL-10."\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## Neural Network Architectures"\n        "We will implement the following architectures:\n        - SimpleCNN\n        - DeepNeuralNetwork\n        - LeNetStyleCNN\n        - MiniResNet"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "import torch\n        import torch.nn as nn\n        import torch.optim as optim\n        import torchvision.transforms as transforms\n        from torchvision import datasets, models\n        import matplotlib.pyplot as plt\n        import numpy as np"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## Model Implementations"\n        "Let's define our models here."\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "class SimpleCNN(nn.Module):\n            def __init__(self):\n                super(SimpleCNN, self).__init__()\n                self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n                self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n                self.fc1 = nn.Linear(64 * 7 * 7, 128)\n                self.fc2 = nn.Linear(128, 10)\n                self.pool = nn.MaxPool2d(2, 2)\n                self.relu = nn.ReLU()\n\n            def forward(self, x):\n                x = self.pool(self.relu(self.conv1(x)))\n                x = self.pool(self.relu(self.conv2(x)))\n                x = x.view(-1, 64 * 7 * 7)\n                x = self.relu(self.fc1(x))\n                x = self.fc2(x)\n                return x"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "class DeepNeuralNetwork(nn.Module):\n            def __init__(self):\n                super(DeepNeuralNetwork, self).__init__()\n                self.fc1 = nn.Linear(28 * 28, 512)\n                self.fc2 = nn.Linear(512, 256)\n                self.fc3 = nn.Linear(256, 128)\n                self.fc4 = nn.Linear(128, 10)\n                self.relu = nn.ReLU()\n\n            def forward(self, x):\n                x = x.view(-1, 28 * 28)\n                x = self.relu(self.fc1(x))\n                x = self.relu(self.fc2(x))\n                x = self.relu(self.fc3(x))\n                x = self.fc4(x)\n                return x"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "class LeNetStyleCNN(nn.Module):\n            def __init__(self):\n                super(LeNetStyleCNN, self).__init__()\n                self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n                self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n                self.fc1 = nn.Linear(16 * 5 * 5, 120)\n                self.fc2 = nn.Linear(120, 84)\n                self.fc3 = nn.Linear(84, 10)\n                self.pool = nn.AvgPool2d(2, 2)\n                self.relu = nn.ReLU()\n\n            def forward(self, x):\n                x = self.pool(self.relu(self.conv1(x)))\n                x = self.pool(self.relu(self.conv2(x)))\n                x = x.view(-1, 16 * 5 * 5)\n                x = self.relu(self.fc1(x))\n                x = self.relu(self.fc2(x))\n                x = self.fc3(x)\n                return x"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "class MiniResNet(nn.Module):\n            def __init__(self):\n                super(MiniResNet, self).__init__()\n                self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n                self.layer1 = self.make_layer(16, 2)\n                self.layer2 = self.make_layer(32, 2)\n                self.fc = nn.Linear(32 * 8 * 8, 10)\n                self.relu = nn.ReLU()\n\n            def make_layer(self, out_channels, blocks):\n                layers = []\n                for _ in range(blocks):\n                    layers.append(nn.Conv2d(16, out_channels, kernel_size=3, padding=1))\n                    layers.append(nn.ReLU())\n                    layers.append(nn.MaxPool2d(2, 2))\n                return nn.Sequential(*layers)\n\n            def forward(self, x):\n                x = self.conv1(x)\n                x = self.layer1(x)\n                x = self.layer2(x)\n                x = x.view(-1, 32 * 8 * 8)\n                x = self.fc(x)\n                return x"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## Training Code"\n        "We will write the training loop for each model on the specified datasets."\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n            model.train()\n            for epoch in range(num_epochs):\n                running_loss = 0.0\n                for images, labels in train_loader:\n                    optimizer.zero_grad()\n                    outputs = model(images)\n                    loss = criterion(outputs, labels)\n                    loss.backward()\n                    optimizer.step()\n                    running_loss += loss.item()\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## Evaluation Functions"\n        "We will implement functions to evaluate the models after training."\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "def evaluate_model(model, test_loader):\n            model.eval()\n            correct = 0\n            total = 0\n            with torch.no_grad():\n                for images, labels in test_loader:\n                    outputs = model(images)\n                    _, predicted = torch.max(outputs.data, 1)\n                    total += labels.size(0)\n                    correct += (predicted == labels).sum().item()\n            return correct / total"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## Results Tables"\n        "We will create tables to summarize the results from training and evaluation."\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## Visualizations"\n        "We will plot graphs to visualize training progress and results."\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## Conclusion"\n        "In this notebook, we have compared various neural network architectures across multiple datasets. The results and visualizations provide insights into their performance and efficiency."\n      ]\n    }\n  ],\n  "metadata": {\n    "kernelspec": {\n      "display_name": "Python 3",\n      "language": "python",\n      "name": "python3"\n    },\n    "language_info": {\n      "codemirror_mode": {\n        "name": "ipython",\n        "version": 3\n      },\n      "file_extension": ".py",\n      "mimetype": "text/x-python",\n      "name": "python",\n      "nbconvert_exporter": "python",\n      "pygments_lexer": "ipython3",\n      "version": "3.8.5"\n    }\n  },\n  "nbformat": 4,\n  "nbformat_minor": 4\n}